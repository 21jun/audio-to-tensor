{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an end-to-end Speech Recognition model in PyTorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibD6bsRPl8Qu"
      },
      "source": [
        "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fXgsDQmK09"
      },
      "source": [
        "## installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfN8o17Bdp2"
      },
      "source": [
        "# !pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKHvy8DmOCQ"
      },
      "source": [
        "## Setting up your data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJs4Bk8FjjO"
      },
      "source": [
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSlhAQnDEA"
      },
      "source": [
        "## The Model\n",
        "Base of of Deep Speech 2 with some personal improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65H1-PCjm-FB"
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuguNEzKnMOn"
      },
      "source": [
        "## The Training and Evaluating Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkqGeOwnPGY"
      },
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    with experiment.train():\n",
        "        for batch_idx, _data in enumerate(train_loader):\n",
        "\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "\n",
        "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
        "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            iter_meter.step()\n",
        "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(spectrograms), data_len,\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "\n",
        "            print(decoded_preds, decoded_targets)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    # experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
        "    # experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
        "    # experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\",\n",
        "        experiment=Experiment(api_key='dummy_key', disabled=True)):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    experiment.log_parameters(hparams)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"data/librispeech\", url=train_url, download=False)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"data/librispeech\", url=test_url, download=False)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=5e-4\n",
        "batch_size=8\n",
        "epochs=1\n",
        "train_url=\"train-clean-100\"\n",
        "test_url=\"test-clean\"\n",
        "experiment=Experiment(api_key='dummy_key', disabled=True)\n",
        "\n",
        "hparams = {\n",
        "    \"n_cnn_layers\": 3,\n",
        "    \"n_rnn_layers\": 5,\n",
        "    \"rnn_dim\": 512,\n",
        "    \"n_class\": 29,\n",
        "    \"n_feats\": 128,\n",
        "    \"stride\":2,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs\n",
        "}\n",
        "\n",
        "experiment.log_parameters(hparams)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "if not os.path.isdir(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "\n",
        "train_dataset = torchaudio.datasets.LIBRISPEECH(\"data/librispeech\", url=train_url, download=False)\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"data/librispeech\", url=test_url, download=True)\n",
        "\n",
        "full_len = len(train_dataset)\n",
        "\n",
        "train_len = int(0.1 * full_len)\n",
        "left = full_len - train_len\n",
        "\n",
        "train_dataset, _ = torch.utils.data.random_split(train_dataset, ( train_len, left))\n",
        "\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=True,\n",
        "                            collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                            **kwargs)\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=False,\n",
        "                            collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                            **kwargs)\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 128, 1285])\ntorch.Size([8, 301])\n[542, 513, 642, 459, 168, 625, 387, 508]\n[195, 148, 301, 227, 67, 247, 105, 193]\n"
          ]
        }
      ],
      "source": [
        "for a in train_loader:\n",
        "    # spectrograms, labels, input_lengths, label_lengths\n",
        "    print(a[0].size())\n",
        "    print(a[1].size())\n",
        "    print(a[2])\n",
        "    print(a[3])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0007, -0.0007, -0.0012,  ...,  0.0050,  0.0059, -0.0002]]),\n",
              " 16000,\n",
              " 'THUS WE ARE MOVED TO STUDY THE DEVELOPMENT OF SEX LIFE IN THE CHILD ALSO AND WE DISCOVER THE FOLLOWING FROM A NUMBER OF SOURCES IN THE FIRST PLACE IT IS A MISTAKE TO DENY THAT THE CHILD HAS A SEXUAL LIFE AND TO TAKE IT FOR GRANTED',\n",
              " 8975,\n",
              " 270782,\n",
              " 77)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "train_loader.dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0007, -0.0007, -0.0012,  ...,  0.0050,  0.0059, -0.0002]]) THUS WE ARE MOVED TO STUDY THE DEVELOPMENT OF SEX LIFE IN THE CHILD ALSO AND WE DISCOVER THE FOLLOWING FROM A NUMBER OF SOURCES IN THE FIRST PLACE IT IS A MISTAKE TO DENY THAT THE CHILD HAS A SEXUAL LIFE AND TO TAKE IT FOR GRANTED\ntorch.Size([1, 128, 1190])\ntorch.Size([1190, 128])\n"
          ]
        }
      ],
      "source": [
        "for (waveform, _, utterance, _, _, _) in train_loader.dataset:\n",
        "    print(waveform, utterance)\n",
        "\n",
        "    print(train_audio_transforms(waveform).size())\n",
        "    print(train_audio_transforms(waveform).squeeze(0).transpose(0, 1).size())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    # (waveform, sample_rate, utterance, speaker_id, chapter_id, utterance_id)\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0262,  0.0145, -0.0055,  ...,  0.0079, -0.0007, -0.0103]]),\n",
              " 16000,\n",
              " 'NOW I DARE SAY YOU ARE THINKING OF MONSIEUR VALANCOURT AND THAT HE MAY HAVE COME AMONG THE ARMIES WHICH THEY SAY ARE COME FROM OUR COUNTRY TO FIGHT AGAINST THIS STATE AND THAT HE HAS MET WITH SOME OF OUR PEOPLE AND IS TAKEN CAPTIVE',\n",
              " 2007,\n",
              " 132570,\n",
              " 15)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_loader.dataset[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jljlejljljljljejleleljleleljlel', 'ljljbjwljleljejeljljejelejejljljljeljljejljljljeljljlejejljljlejljelejljlejljljljleleleljleleljljlelelelelelel', 'ljljwljejljljljljljljejejljlelejelelelejljljlelelelelelelelelel'] ['the chaos in which his ardour extinguished itself was a cold indifferent knowledge of himself', 'at most by an alms given to a beggar whose blessing he fled from he might hope wearily to win for himself some measure of actual grace', 'well now ennis i declare you have a head and so has my stick', 'on saturday mornings when the sodality met in the chapel to recite the little office his place was a cushioned kneeling desk at the right of the altar from which he led his wing of boys through the responses', 'her eyes seemed to regard him with mild pity her holiness a strange light glowing faintly upon her frail flesh did not humiliate the sinner who approached her', 'if ever he was impelled to cast sin from him and to repent the impulse that moved him was the wish to be her knight', 'he tried to think how it could be', 'but the dusk deepening in the schoolroom covered over his thoughts the bell rang']\n",
            "['lblbelblllllblblbl', 'lblelellblelelelbelelelelyelellyjlelelblel', 'lblelelejlblelelblbeleljlylelelelelelelelelelyjelelblelejlelel', 'lblelelelejljljleljeleblbeleljljeleljljyejljleleleleleleleljleleleleleleleleleljeljleljlylelelejljlelelelelel', 'lelelejljejejljeleejleljejejljejljleleleleljleleleleljllelejlejeljlelelelejlejljlyjeljlelyleleleljlelejljljleleleleleljlelelel', 'ljlejeleljljejejewljejejleljejljejljlelejljelelejeleleljejejejljlejejlejejljlejljeljlelejelejeljejljelelejeljlejleljlelelejljleleleleleljlejeleleleleleljljejlelejlelelelel', 'ljljlwejeljnjejejyjejleljejejlejeljeljejejejlejejejejejejejljlejljeljlelejejejelyljejejlejljlejejeljlelejljljejlejelewejejljeleleljeleljleleljejejejejleljlejleleleljlelelelelelelel', 'ljljwjwjlwjljljnjejwjnjejljljljleljlylwjejljejljljljljejljwjeljeljlelejljljleljejlejljljlejljeljljljlejejlejljleljlejelel'] ['then you can ask him questions on the catechism dedalus', 'stephen leaning back and drawing idly on his scribbler listened to the talk about him which heron checked from time to time by saying', 'it was strange too that he found an arid pleasure in following up to the end the rigid lines of the doctrines of the church and penetrating into obscure silences only to hear and feel the more deeply his own condemnation', 'the sentence of saint james which says that he who offends against one commandment becomes guilty of all had seemed to him first a swollen phrase until he had begun to grope in the darkness of his own state', 'if a man had stolen a pound in his youth and had used that pound to amass a huge fortune how much was he obliged to give back the pound he had stolen only or the pound together with the compound interest accruing upon it or all his huge fortune', 'if a layman in giving baptism pour the water before saying the words is the child baptized', 'how comes it that while the first beatitude promises the kingdom of heaven to the poor of heart the second beatitude promises also to the meek that they shall possess the land', 'why was the sacrament of the eucharist instituted under the two species of bread and wine if jesus christ be present body and blood soul and divinity in the bread alone and in the wine alone']\n",
            "['lbllblbl', 'lblblblllllll', 'lblblellljlelelelelelelel', 'lbleleleljejleljljelelelelelelelel', 'lblelelelejejljeleleljejejelejleleleleleleljleleljljl', 'lblelelewlejeljewelejelejejljeljlelelejljleleljleleleleljlejlelel', 'ljljelewlejeljewljejeljejljljejljljejljljleljejlelejelejlelel', 'ljljljwjwljljljejljejejlelejljljlnlejejljejlejleljlelejljljeleljljl'] ['if the wine change into vinegar and the host crumble into corruption after they have been consecrated is jesus christ still present under their species as god and as man', 'a gentle kick from the tall boy in the bench behind urged stephen to ask a difficult question', 'the rector did not ask for a catechism to hear the lesson from', 'he clasped his hands on the desk and said', 'the retreat will begin on wednesday afternoon in honour of saint francis xavier whose feast day is saturday', 'on friday confession will be heard all the afternoon after beads', 'beware of making that mistake', \"stephen's heart began slowly to fold and fade with fear like a withering flower\"]\n",
            "['llllbll', 'lellllelll', 'lelelllelelleleljl', 'lelelleleljljleljleljelejel', 'leleleleljleleljleljljelejel', 'lejljelejljejlejljljljljelejejeljljlejlel', 'ljejwljewelejejnljljljelejljljljejeljljleljljejlejelelel', 'ljljljejwjewjwjnjljejljejejejljljljljljejlejleljljeleljljl'] ['he is called as you know the apostle of the indies', 'a great saint saint francis xavier', 'the rector paused and then shaking his clasped hands before him went on', 'he had the faith in him that moves mountains', 'a great saint saint francis xavier', 'in the silence their dark fire kindled the dusk into a tawny glow', 'he could wait no longer', 'for a full hour he had paced up and down waiting but he could wait no longer']\n",
            "['lbllblbl', 'lblelellelelelel', 'lblelelelelelelelyleyelelelelelelejl', 'lblblelelejlelelelyjejeleleljljelelejelbljlelelelel', 'lblelelelelejleleleyjejeleljlejljelejlejelelbeljeleleleleljlelelelel', 'lelwejeleljljejlelejljeleleyjejelejeljleljljejljejlelejejejlejlejejlejelelejejlejlelelelelelelelelelelelelelelelelelelelel', 'ljejlwlejeljejljeljeljljejljwjeljeleljljljlejejejejejejelejejljejljejeleljleljljeleleleljlelelelelelelelelelelelelejlelelelelelelelelelelelelelelelelelelel', 'ljljwnljejejljljljljenjlejejejljljejleljejejljejlelejeljlejeleljleleleljeljljlejejlejeljljlejejejeljljljljljlelelelelelelelelejeleleleleljlelelelelel'] [\"he set off abruptly for the bull walking rapidly lest his father's shrill whistle might call him back and in a few moments he had rounded the curve at the police barrack and was safe\", 'the university', 'pride after satisfaction uplifted him like long slow waves', 'whose feet are as the feet of harts and underneath the everlasting arms', 'the pride of that dim image brought back to his mind the dignity of the office he had refused', 'soon the whole bridge was trembling and resounding', 'the uncouth faces passed him two by two stained yellow or red or livid by the sea and as he strove to look at them with ease and indifference a faint stain of personal shame and commiseration rose to his own face', 'angry with himself he tried to hide his face from their eyes by gazing down sideways into the shallow swirling water under the bridge but he still saw a reflection therein of their top heavy silk hats and humble tape like collars and loosely hanging clerical clothes brother hickey']\n",
            "['lblblblblbl', 'lblblbllelel', 'lblelelcelellelelelelelelel', 'lelelelejlelelejleleleleleleleleljlel', 'leleleljeleljlejlelelelelejleleljleleljeleljl', 'lejelelelelejeleljlwelejleljejleljeleleleleleljeleleljlelelelelejlejljleleljl', 'lejejlejljljlejejljljlejlwejlelejejljejljljlejlejljeleljljleljejeleljleleljljleljeljljleleleljelejejljljljeljlejejeleljlelelelelelejljlelel', 'ljejewjejejljljejwjljewjljejljljljljejwjejljljljljleljlejejljlelejejwjeljejljljljeleljeljljljljljljljljleleleleljlelejelelelel'] ['brother mac ardle brother keogh', 'their piety would be like their names like their faces like their clothes and it was idle for him to tell himself that their humble and contrite hearts it might be paid a far richer tribute of devotion than his had ever been a gift tenfold more acceptable than his elaborate adoration', \"it was idle for him to move himself to be generous towards them to tell himself that if he ever came to their gates stripped of his pride beaten and in beggar's weeds that they would be generous towards him loving him as themselves\", 'idle and embittering finally to argue against his own dispassionate certitude that the commandment of love bade us not to love our neighbour as ourselves with the same amount and intensity of love but to love him as ourselves with the same kind of love', 'the phrase and the day and the scene harmonized in a chord', 'words was it their colours', 'they were voyaging across the deserts of the sky a host of nomads on the march voyaging high over ireland westward bound', 'the europe they had come from lay out there beyond the irish sea europe of strange tongues and valleyed and woodbegirt and citadelled and of entrenched and marshalled races']\n",
            "['lblbl', 'l', 'lelelel', 'leleleleljlelelelelel', 'lejlelelejelejlelelelelelelelelelelelel', 'lewenejlelejewelelejejewlejeleleljljelejljeljelelelejeleleleleleleljlelel', 'lelejlwejelelejewelejejewljejelelwljljljeljljejljeljelejelejeljleleleleleleljljljeljelelelelel', 'ljljwnwejeleljewnlejwjwjwlejeljlejejejejejljlelelejlejljljljleljljljleljeljljleljleljleljljljl'] ['again again', 'a voice from beyond the world was calling', 'hello stephanos here comes the dedalus', 'their diving stone poised on its rude supports and rocking under their plunges and the rough hewn stones of the sloping breakwater over which they scrambled in their horseplay gleamed with cold wet lustre', 'he stood still in deference to their calls and parried their banter with easy words', 'it was a pain to see them and a sword like pain to see the signs of adolescence that made repellent their pitiable nakedness', 'stephanos dedalos', 'a moment before the ghost of the ancient kingdom of the danes had looked forth through the vesture of the hazewrapped city']\n",
            "['lblblblblblblblbl', 'lelelyleblblelyelylylblelylelylelel', 'lejleleleleleylylelelelejlelyelyleleleleleljlejleyelelelylelelemlelel', 'ljlejleleceleyleyjeleleljlejlelyljljleleleljljleleljleljljlelejlyjleleljyleleljljlejleljljl', 'ljljljljlejlejeljeyjejljeleleljljejljljljlelyljljleljleleljljljljeleljljljleljljljljljljejlejljljejljljl', 'ljljljlewjljejeleljejejljelejljljeljljljljljljljleljljljljleljljljlejljljljleljejejljljejlejlelejljljleleljljeljljljl', 'ljljljejeljejejljejljljlejljljljejleljljljljljljljljljleljejejeljlejelejlejljlejljljeljejljeljljljljleljlelelelelelelel', 'ljljljljljljlejljeljejljlejljljljejejljljljejeljljljljljljljlejeljljlelejlelelelejl'] ['you will find me continually speaking of four men titian holbein turner and tintoret in almost the same terms', 'they unite every quality and sometimes you will find me referring to them as colorists sometimes as chiaroscurists', 'by being studious of color they are studious of division and while the chiaroscurist devotes himself to the representation of degrees of force in one thing unseparated light the colorists have for their function the attainment of beauty by arrangement of the divisions of light', 'my first and principal reason was that they enforced beyond all resistance on any student who might attempt to copy them this method of laying portions of distinct hue side by side', 'some of the touches indeed when the tint has been mixed with much water have been laid in little drops or ponds so that the pigment might crystallize hard at the edge', \"it is the head of a parrot with a little flower in his beak from a picture of carpaccio's one of his series of the life of saint george\", 'then he comes to the beak of it', 'the brown ground beneath is left for the most part one touch of black is put for the hollow two delicate lines of dark gray define the outer curve and one little quivering touch of white draws the inner edge of the mandible']\n",
            "['llblblblylbl', 'leblbleleellcllblelelelelel', 'llelbleleljleljelbjljlelelylylel', 'lelbljleljlelelelejejljljljeleleleljljljlejljljleljleljl', 'leleljljejlejelelejljljyjljleljejlejejljljljejljljleljljljleljlelejel', 'ljeleljejljejlelejljeljljejljejleljljljlejeleljljeleljljljljljlejljljljljljljljleljleleleljlelelel', 'ljljljejejlejljejejejeljljeljljljljljelejejljleljljleljlelejljejejljejejelejljljleleleljljljlelejljlejlejelelelejejlejlelelejeleleljeljljlelelelel', 'njbjljljejejeljljljljljljejeljlejljeljljljejljejljljljljljleljlejljljljljljeljejljljljljljelejejljlejljljejlelejljejlejeljljljlejljejeljejlejeleleleljljl'] ['for believe me the final philosophy of art can only ratify their opinion that the beauty of a cock robin is to be red and of a grass plot to be green and the best skill of art is in instantly seizing on the manifold deliciousness of light which you can only seize by precision of instantaneous touch', 'now you will see in these studies that the moment the white is inclosed properly and harmonized with the other hues it becomes somehow more precious and pearly than the white paper and that i am not afraid to leave a whole field of untreated white paper all round it being sure that even the little diamonds in the round window will tell as jewels if they are gradated justly', 'but in this vignette copied from turner you have the two principles brought out perfectly', 'they are beyond all other works that i know existing dependent for their effect on low subdued tones their favorite choice in time of day being either dawn or twilight and even their brightest sunsets produced chiefly out of gray paper', 'it may be that a great colorist will use his utmost force of color as a singer his full power of voice but loud or low the virtue is in both cases always in refinement never in loudness', 'it must remember be one or the other', 'do not therefore think that the gothic school is an easy one', 'the law of that school is that everything shall be seen clearly or at least only in such mist or faintness as shall be delightful and i have no doubt that the best introduction to it would be the elementary practice of painting every study on a golden ground']\n",
            "['lblylblblblblblllblbl', 'leblelelelbelelellelcelellelel', 'leleelejelbeleleleleelelelleleleleleleleljelel', 'lejleljljelejeljljejlwlelelelejljelljleljeljlejleljljleleljlelelelelelejleljljejljlejeljljljlel', 'leljejlwlejljeleleljljljejljljlelwejelejleljejejljeljljljljlelejlejeljleleljlejeljejejljleljljljljlemleljleljljejljlwejljljljljleleljl', 'lelwljljljljlwjejeljejljljljleljejeljljljejljejeljlejlejejljeljlejejejlejejljljejejeljljljljljejlmjljlejljljejljwjeljmljljljljlelejljljljljljleljl', 'leljljljlwljljeljljwjejljejljljwljejejljejljljljljejejljljljljljljejljljljljejljljljljljljljljlelejljljljejljljleleljljljlelelelelel', 'jljwjljljwjljljljljljljljljljljljljljljejlejljljljljljljleleleleleleleleleleleleljl'] [\"this at once compels you to understand that the work is to be imaginative and decorative that it represents beautiful things in the clearest way but not under existing conditions and that in fact you are producing jeweler's work rather than pictures\", 'that a style is restrained or severe does not mean that it is also erroneous', 'in all early gothic art indeed you will find failure of this kind especially distortion and rigidity which are in many respects painfully to be compared with the splendid repose of classic art', 'the large letter contains indeed entirely feeble and ill drawn figures that is merely childish and failing work of an inferior hand it is not characteristic of gothic or any other school', 'but observe you can only do this on one condition that of striving also to create in reality the beauty which you seek in imagination', 'it will be wholly impossible for you to retain the tranquillity of temper and felicity of faith necessary for noble purist painting unless you are actively engaged in promoting the felicity and peace of practical life', 'you must look at him in the face fight him conquer him with what scathe you may you need not think to keep out of the way of him', 'the colorist says first of all as my delicious paroquet was ruby so this nasty viper shall be black and then is the question can i round him off even though he is black and make him slimy and yet springy and close down clotted like a pool of black blood on the earth all the same']\n",
            "['lblblblblblylbl', 'lbllbllblblelbllylellelylyebelelel', 'lellelelbllelelelelejelelel', 'lellelelelelejlelelelelejljl', 'leleleleljleleljlejljljlmljleljljljl', 'lwjljljlejeleljljejljleleljleljljleljljljl', 'ljlwlwjljljljljljljejejljljljljleleleleleljlelelelelel', 'lulujljljwjwjleleleleljljljljljljljljeljljleleleleleleleljleleljljlelelelelel'] ['nothing will be more precious to you i think in the practical study of art than the conviction which will force itself on you more and more every hour of the way all things are bound together little and great in spirit and in matter', 'you know i have just been telling you how this school of materialism and clay involved itself at last in cloud and fire', \"here is an equally typical greek school landscape by wilson lost wholly in golden mist the trees so slightly drawn that you don't know if they are trees or towers and no care for color whatever perfectly deceptive and marvelous effect of sunshine through the mist apollo and the python\", 'now here is raphael exactly between the two trees still drawn leaf by leaf wholly formal but beautiful mist coming gradually into the distance', \"well then last here is turner's greek school of the highest class and you define his art absolutely as first the displaying intensely and with the sternest intellect of natural form as it is and then the envelopment of it with cloud and fire\", 'only there are two sorts of cloud and fire', 'he knows them both', \"there's one and there's another the dudley and the flint\"]\n",
            "['lblbllellblbl', 'llelelblllell', 'ljlelbelllelbljljlelelelel', 'ljlejlelelewjljlelbljljyejljljleleljleleleleleljel', 'lejlejlewjljljljljemeljleljljljljljejejlejejeljeleljljljlel', 'leljeljljljwjlejwjejljljmjljljleljljljljljejejejejljljljelejeljljljeleljljljlelelelelel', 'lejljljljljljwjljljljejljejwjejejejljejleljljljljljljljljlelelelelelelelelel', 'ljwlwjwjljwjejljljljljljljljljlelelelelelelelelelelelelelel'] ['it is only a pencil outline by edward burne jones in illustration of the story of psyche it is the introduction of psyche after all her troubles into heaven', 'every plant in the grass is set formally grows perfectly and may be realized completely', 'exquisite order and universal with eternal life and light this is the faith and effort of the schools of crystal and you may describe and complete their work quite literally by taking any verses of chaucer in his tender mood and observing how he insists on the clearness and brightness first and then on the order', \"thus in chaucer's dream\", 'in both these high mythical subjects the surrounding nature though suffering is still dignified and beautiful', 'every line in which the master traces it even where seemingly negligent is lovely and set down with a meditative calmness which makes these two etchings capable of being placed beside the most tranquil work of holbein or duerer', 'but now here is a subject of which you will wonder at first why turner drew it at all', 'it has no beauty whatsoever no specialty of picturesqueness and all its lines are cramped and poor']\n",
            "['lblbllelyl', 'llellyelelel', 'lelleleljllelelelelel', 'lelleleljljleljlelelelelelelelelejlelelejelelelel', 'ljlelleljeljljleljljlelelelejeljelejlelelejeleleljl', 'ljlewleleljeljleljljleljejejelelejlelelejejelelejlel', 'ljlejeleweleljljeljlnjeljejljleljejelejljeljejelejejeljlelejeljljlel', 'ljejejenlweljljejejeljljeleljwjejejljljljeljejljljljejljljljljljljljljleljleljlel'] ['the crampness and the poverty are all intended', 'it is a gleaner bringing down her one sheaf of corn to an old watermill itself mossy and rent scarcely able to get its stones to turn', 'the scene is absolutely arcadian', \"see that your lives be in nothing worse than a boy's climbing for his entangled kite\", 'it will be well for you if you join not with those who instead of kites fly falcons who instead of obeying the last words of the great cloud shepherd to feed his sheep live the lives how much less than vanity of the war wolf and the gier eagle', 'also a popular contrivance whereby love making may be suspended but not stopped during the picnic season', 'harangue the tiresome product of a tireless tongue', 'angor pain painful to hear']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-e461f5d21fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-74618d82e8ce>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, criterion, epoch, iter_meter, experiment)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mtest_cer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mtest_wer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-3be0ba5e69e1>\u001b[0m in \u001b[0;36mcer\u001b[0;34m(reference, hypothesis, ignore_case, remove_space)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \"\"\"\n\u001b[1;32m    179\u001b[0m     edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n\u001b[0;32m--> 180\u001b[0;31m                                          remove_space)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mref_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-3be0ba5e69e1>\u001b[0m in \u001b[0;36mchar_errors\u001b[0;34m(reference, hypothesis, ignore_case, remove_space)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0medit_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_levenshtein_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medit_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-3be0ba5e69e1>\u001b[0m in \u001b[0;36m_levenshtein_distance\u001b[0;34m(ref, hyp)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0ms_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mi_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0md_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "# set blank\n",
        "criterion = nn.CTCLoss(blank=28).to(device)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                        steps_per_epoch=int(len(train_loader)),\n",
        "                                        epochs=hparams['epochs'],\n",
        "                                        anneal_strategy='linear')\n",
        "\n",
        "iter_meter = IterMeter()\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "    test(model, device, test_loader, criterion, epoch, iter_meter, experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"librispeech/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load(\"librispeech/model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-6.8706, -5.8052, -1.5170,  ..., -3.5881, -7.9626, -3.0825],\n         [-6.9669, -5.8632, -1.4912,  ..., -3.6018, -8.0781, -3.0979],\n         [-7.0027, -5.8804, -1.4784,  ..., -3.6025, -8.1237, -3.0946],\n         ...,\n         [-6.9849, -5.8595, -1.4754,  ..., -3.5694, -8.1116, -3.0736],\n         [-6.9258, -5.8116, -1.4878,  ..., -3.5303, -8.0334, -3.0597],\n         [-6.7182, -5.6349, -1.5411,  ..., -3.4202, -7.7381, -3.0196]],\n\n        [[-6.5475, -4.1012, -3.1179,  ..., -4.9172, -9.2291, -1.6324],\n         [-6.7298, -4.2143, -3.1724,  ..., -5.0657, -9.5914, -1.6428],\n         [-6.7719, -4.2363, -3.1883,  ..., -5.0975, -9.6736, -1.6366],\n         ...,\n         [-6.7724, -4.2350, -3.1901,  ..., -5.0944, -9.6711, -1.6178],\n         [-6.7414, -4.2210, -3.1774,  ..., -5.0712, -9.6174, -1.6093],\n         [-6.6330, -4.1908, -3.1346,  ..., -5.0021, -9.4601, -1.6129]],\n\n        [[-7.4286, -2.6372, -3.7349,  ..., -5.1281, -9.0110, -0.4579],\n         [-7.4181, -2.6538, -3.7386,  ..., -5.1337, -9.0137, -0.4541],\n         [-7.4146, -2.6557, -3.7392,  ..., -5.1348, -9.0136, -0.4536],\n         ...,\n         [-7.4076, -2.6556, -3.7454,  ..., -5.1330, -9.0043, -0.4533],\n         [-7.4008, -2.6541, -3.7485,  ..., -5.1298, -8.9942, -0.4539],\n         [-7.4077, -2.6446, -3.7479,  ..., -5.1471, -9.0152, -0.4534]],\n\n        ...,\n\n        [[-7.4285, -2.6373, -3.7349,  ..., -5.1281, -9.0109, -0.4579],\n         [-7.4180, -2.6538, -3.7386,  ..., -5.1337, -9.0137, -0.4542],\n         [-7.4145, -2.6556, -3.7392,  ..., -5.1347, -9.0136, -0.4537],\n         ...,\n         [-7.4075, -2.6556, -3.7454,  ..., -5.1329, -9.0043, -0.4533],\n         [-7.4007, -2.6540, -3.7485,  ..., -5.1298, -8.9942, -0.4539],\n         [-7.4075, -2.6446, -3.7479,  ..., -5.1471, -9.0151, -0.4534]],\n\n        [[-7.4285, -2.6373, -3.7349,  ..., -5.1281, -9.0109, -0.4579],\n         [-7.4180, -2.6538, -3.7386,  ..., -5.1337, -9.0137, -0.4542],\n         [-7.4145, -2.6556, -3.7392,  ..., -5.1347, -9.0136, -0.4537],\n         ...,\n         [-7.4075, -2.6556, -3.7454,  ..., -5.1329, -9.0043, -0.4533],\n         [-7.4007, -2.6540, -3.7485,  ..., -5.1298, -8.9942, -0.4539],\n         [-7.4075, -2.6445, -3.7479,  ..., -5.1471, -9.0151, -0.4534]],\n\n        [[-7.4285, -2.6373, -3.7349,  ..., -5.1281, -9.0109, -0.4579],\n         [-7.4180, -2.6538, -3.7386,  ..., -5.1337, -9.0137, -0.4542],\n         [-7.4145, -2.6556, -3.7392,  ..., -5.1347, -9.0136, -0.4537],\n         ...,\n         [-7.4075, -2.6556, -3.7454,  ..., -5.1329, -9.0043, -0.4533],\n         [-7.4007, -2.6540, -3.7485,  ..., -5.1298, -8.9942, -0.4539],\n         [-7.4075, -2.6445, -3.7479,  ..., -5.1471, -9.0151, -0.4534]]],\n       device='cuda:0', grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = 'cuda'\n",
        "model.eval()\n",
        "for _data in train_loader:\n",
        "    spectrograms, labels, input_lengths, label_lengths = _data \n",
        "    spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "    output = model(spectrograms)  # (batch, time, n_class)\n",
        "    output = F.log_softmax(output, dim=2)\n",
        "    output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "    print(output)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 247])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "labels.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([647, 8, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "output.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.,  1.,  3.,  6., 13., 10.,  6., 23.,  6.,  1., 21.,  9.,  2., 21.,\n",
              "         1., 21., 16., 16.,  1., 21.,  9.,  6.,  1., 15., 22., 14.,  3.,  6.,\n",
              "        19.,  1., 16.,  7.,  1., 21.,  9., 16., 20.,  6.,  1., 24.,  9., 16.,\n",
              "         1.,  9.,  2., 23.,  6.,  1., 17., 19., 16., 14., 10., 20.,  6.,  5.,\n",
              "         1., 21., 16.,  1.,  5., 16.,  1.,  2., 20.,  1., 11.,  6., 20., 22.,\n",
              "        20.,  1., 24., 16., 22., 13.,  5.,  1., 10., 20.,  1., 10., 15.,  4.,\n",
              "        19.,  6.,  2., 20., 10., 15.,  8.,  1., 10.,  7.,  1., 24.,  6.,  1.,\n",
              "        16., 15.,  4.,  6.,  1.,  9.,  2., 23.,  6.,  1., 20.,  2., 26.,  1.,\n",
              "         7., 10., 23.,  6.,  1.,  9., 22., 15.,  5., 19.,  6.,  5.,  1., 20.,\n",
              "        22.,  4.,  9.,  1.,  5., 10., 20.,  4., 10., 17., 13.,  6., 20.,  1.,\n",
              "        10., 15.,  1., 19.,  2., 26., 14., 16., 15.,  5.,  1., 21.,  9.,  6.,\n",
              "         1., 20.,  2., 13., 16., 16., 15.,  1., 10., 20.,  1.,  5., 16., 16.,\n",
              "        14.,  6.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "sample = labels.detach().cpu()[0]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "isample = [int(x.item()) for x in sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i believe that too the number of those who have promised to do as jesus would is increasing if we once have say five hundred such disciples in raymond the saloon is doomed''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\""
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "text_transform.int_to_text(isample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'28'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-ce78192ca4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'28'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '28'"
          ]
        }
      ],
      "source": [
        "text_transform.index_map['28']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_sample = output.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  9, 28,  ..., 28, 28, 28],\n",
              "        [ 2,  9, 28,  ..., 28, 28, 28],\n",
              "        [ 2,  9, 28,  ..., 28, 28, 28],\n",
              "        ...,\n",
              "        [ 2,  9, 28,  ..., 28, 28, 28],\n",
              "        [ 2,  9, 28,  ..., 28, 28, 28],\n",
              "        [ 2, 28, 28,  ..., 28, 28, 28]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "torch.argmax(out_sample, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "decodes, targets = GreedyDecoder(output=output.transpose(0, 1), labels=labels, label_lengths=label_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ah', 'ah', 'ah', 'ah', 'ah', 'ah', 'ah', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "decodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i believe that too the number of those who have promised to do as jesus would is increasing if we once have say five hundred such disciples in raymond the saloon is doomed',\n",
              " 'take from the fire add the yolks of four eggs beaten with the juice of a lemon and three tablespoonfuls of butter bring to the boil add a dozen parboiled oysters pour over the fish and serve baked perch',\n",
              " 'we want the best in two races and civilizations in exchange for what we have lost some of us have entered upon every known professional career such as medicine law the ministry education and the sciences',\n",
              " \"and anyway i'm thankful to have julia take a fancy to anybody it leaves us a great deal freer to do as we like i should think that you would see that yourself oh well said nora laughing the whole thing is not worth quarreling about\",\n",
              " 'and there the comrade knocked upon the door and asked for lodging',\n",
              " 'as he had not been able to bend down for fear of betraying himself he had not cut the bonds of his left leg the ruffians had recovered from their first surprise be easy',\n",
              " 'i awoke to a renewed consciousness of the woful fact i carried it with me into all companies into all occupations hardly anything had power to cause me even a few minutes oblivion of it',\n",
              " \"so you can judge pretty well for yourself guess he had a pretty good bird's eye view of the whole thing said joe as they passed on to meet again before mess except for spasmodic outbursts here and there the trench duel had almost entirely subsided\"]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}